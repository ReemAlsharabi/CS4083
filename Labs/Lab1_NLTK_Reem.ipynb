{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReemAlsharabi/CS4083/blob/main/Labs/Lab1_NLTK_Reem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: Reem Alsharabi\n",
        "\n",
        "ID: S20106353"
      ],
      "metadata": {
        "id": "AdHYseJwy-Q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This week is about getting started with powerful tools that will underlie many of the skills you learn in the course. Much of the effort is in setting up your programming environment: the lab questions will ensure that it is done correctly and help you grow familiar with it.\n",
        "In this course we'll be using the Python programming language, using an innovative environment called Jupyter Notebooks.\n",
        "Your environment is similar to your local workspace. Look at your desk: how do you organize your pens, paper, mouse, monitor? Or maybe you have a barebones workspace, working at a coffee shop or kitchen table with only a cup of coffee. In the same way, you can have many different environments for how you work with Python: working on a command line, or running scripts. Jupyter Notebooks is an environment that gives you an interactive, browser based version of Python. It allows you to play with code in a way that gives you immediate feedback, and allows you to break, tinker, and retry."
      ],
      "metadata": {
        "id": "ok5VQes1SMch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin"
      ],
      "metadata": {
        "id": "N0Rvd-0PHGkW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHiXz51pIryu",
        "outputId": "430a3397-4716-42be-bc29-bad1a76e0bf9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom class for NLTK text preprocessing"
      ],
      "metadata": {
        "id": "E-Q1YI9FHKtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NLTKPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        self.stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        preprocessed_X = []\n",
        "        for text in X:\n",
        "            tokens = word_tokenize(text)\n",
        "            filtered_tokens = [token for token in tokens if token.lower() not in self.stop_words]\n",
        "            lemmatized_tokens = [self.lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
        "            preprocessed_text = ' '.join(lemmatized_tokens)\n",
        "            preprocessed_X.append(preprocessed_text)\n",
        "        return preprocessed_X"
      ],
      "metadata": {
        "id": "FJKLxs7tSLPI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the pipeline"
      ],
      "metadata": {
        "id": "QSyMu_AxHgx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    (\"preprocess\", NLTKPreprocessor())\n",
        "])"
      ],
      "metadata": {
        "id": "0nEt031BHe58"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the input text"
      ],
      "metadata": {
        "id": "Ip7KXUjIHltM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=[\"This week is about getting started with powerful tools that will underlie many of the skills you learn in the course. Much of the effort is in setting up your programming environment: the lab questions will ensure that it is done correctly and help you grow familiar with it. In this course we'll be using the Python programming language, using an innovative environment called Jupyter Notebooks.Your environment is similar to your local workspace. Look at your desk: how do you organize your pens, paper, mouse, monitor? Or maybe you have a barebones workspace, working at a coffee shop or kitchen table with only a cup of coffee. In the same way, you can have many different environments for how you work with Python: working on a command line, or running scripts. Jupyter Notebooks is an environment that gives you an interactive, browser based version of Python. It allows you to play with code in a way that gives you immediate feedback, and allows you to break, tinker, and retry.\"]"
      ],
      "metadata": {
        "id": "GkaPidb5Hl6P"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fit the pipeline to the data"
      ],
      "metadata": {
        "id": "rL5uzPqrHud8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_text = pipeline.transform(text)"
      ],
      "metadata": {
        "id": "BRlftqX9HunU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnv2yigxIETL",
        "outputId": "ff8eebea-9aa5-4a8b-e827-00f4e00f69d9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"week getting started powerful tool underlie many skill learn course . Much effort setting programming environment : lab question ensure done correctly help grow familiar . course 'll using Python programming language , using innovative environment called Jupyter Notebooks.Your environment similar local workspace . Look desk : organize pen , paper , mouse , monitor ? maybe barebones workspace , working coffee shop kitchen table cup coffee . way , many different environment work Python : working command line , running script . Jupyter Notebooks environment give interactive , browser based version Python . allows play code way give immediate feedback , allows break , tinker , retry .\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lab, a custom class/transformer NLTKPreprocessor is defined, which performs NLTK-based text preprocessing including tokenization, stopword removal, and lemmatization. The transformer is integrated into scikit-learn's Pipeline. The input text is processed using the transform() method of the pipeline, and the preprocessed text is printed.\n",
        "\n",
        "This approach allows you to utilize NLTK's text preprocessing functionality within scikit-learn's pipeline framework while excluding the modeling or prediction steps."
      ],
      "metadata": {
        "id": "zH_6WL2NJPfY"
      }
    }
  ]
}